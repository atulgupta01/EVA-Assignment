{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2S10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jesYdPhYRbhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import random, os, time\n",
        "\n",
        "\n",
        "import ai, map\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePvPgzP3WSTe",
        "colab_type": "code",
        "outputId": "4857e072-3785-4e2b-8ce6-91c3174fa467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "!python -V\n",
        "\n",
        "print(device)\n",
        "\n",
        "import cv2 as cv\n",
        "print(cv.__version__)\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n",
            "Python 3.6.9\n",
            "cuda\n",
            "4.1.2\n",
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikf0RIYlSaRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "car_file = 'car.jpg'\n",
        "city_file = 'citymap.png'\n",
        "city_map_file = \"MASK1.png\"\n",
        "car_img = cv.imread(car_file)\n",
        "car1 = map.car(0,0,0)\n",
        "city1 = map.city(city_file)\n",
        "citymap1 = map.city(city_map_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0n7Ghq6FjT6",
        "colab_type": "text"
      },
      "source": [
        "**Function to evaluates the policy by calculating its average reward over 10 episodes**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0USH5d42NRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mkdir(base, name):\n",
        "    path = os.path.join(base, name)\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    return path\n",
        "\n",
        "def evaluate_policy(policy, eval_episodes=5):\n",
        "  avg_reward = 0\n",
        "  for count in range(eval_episodes):\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "      action = policy.select_action(np.array(obs))\n",
        "      obs, reward, done = env.step(action)\n",
        "      avg_reward += reward\n",
        "      #print(\"avg_reward = \", avg_reward)\n",
        "  avg_reward /= eval_episodes\n",
        "  print (\"---------------------------------------\")\n",
        "  print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
        "  print (\"---------------------------------------\")\n",
        "  return avg_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSMhS7GMPgl",
        "colab_type": "code",
        "outputId": "ad4798e3-7531-40e1-dfa1-1a66071e5016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9S1tB5wHlQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "rb_file = \"/content/drive/My Drive/EVA_Endgame_Model/rb.pickle\"\n",
        "\n",
        "def save_rb(replay_buffer, rb_file, iteration):\n",
        "\n",
        "    with open(rb_file, 'wb') as handle:\n",
        "        pickle.dump(replay_buffer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "    f = open(\"/content/drive/My Drive/EVA_Endgame_Model/iteration_count.txt\", \"w\")\n",
        "    f.write(str(iteration))\n",
        "    f.close()\n",
        "\n",
        "def load_rb(rb_file):    \n",
        "\n",
        "    f = open(\"/content/drive/My Drive/EVA_Endgame_Model/iteration_count.txt\", \"rt\")\n",
        "    #print(f.read())\n",
        "    count = f.read()\n",
        "\n",
        "    with open(rb_file, 'rb') as handle:\n",
        "        replay_buffer1 = pickle.load(handle)\n",
        "        \n",
        "    return replay_buffer1, count\n",
        "\n",
        "def update_stats(total_timesteps, episode_num, episode_reward, done, on_road_count, off_road_count):\n",
        "\n",
        "    f = open(\"/content/drive/My Drive/EVA_Endgame_Model/stats.csv\", \"a\")\n",
        "    text = str(total_timesteps) + \", \" \n",
        "    text = text + str(episode_num) + \", \"\n",
        "    text = text + str(episode_reward) + \", \"\n",
        "    text = text + str(done) + \", \"\n",
        "    text = text + str(on_road_count) + \", \"\n",
        "    text = text + str(off_road_count) + \"\\n\"\n",
        "    f.write(text)\n",
        "    f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpCwIaoM2Pwo",
        "colab_type": "code",
        "outputId": "47bcf411-5ad4-42b4-e9ba-95f761eb11ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "env = map.env(car1, city1, citymap1, car_img) # Instantiate the environment\n",
        "seed = 8 # Random seed number\n",
        "start_timesteps = 1e4 # Number of iterations/timesteps before which the model randomly chooses an action, and after which it starts to use the policy network\n",
        "eval_freq = 5e3 # How often the evaluation step is performed (after how many timesteps)\n",
        "max_timesteps = 5e5 # Total number of iterations/timesteps\n",
        "save_models = False # Boolean checker whether or not to save the pre-trained model\n",
        "expl_noise = 0.1 # Exploration noise - STD value of exploration Gaussian noise\n",
        "batch_size = 100 # Size of the batch\n",
        "discount = 0.99 # Discount factor gamma, used in the calculation of the total discounted reward\n",
        "tau = 0.005 # Target network update rate\n",
        "policy_noise = 0.2 # STD of Gaussian noise added to the actions for the exploration purposes\n",
        "noise_clip = 0.5 # Maximum value of the Gaussian noise added to the actions (policy)\n",
        "policy_freq = 2 # Number of iterations to wait before the policy network (Actor model) is updated\n",
        "episode_reward = 0\n",
        "episode_timesteps = 0\n",
        "\n",
        "\n",
        "file_name = \"%s_%s\" % (\"TD3_car\", str(seed))\n",
        "print (\"---------------------------------------\")\n",
        "print (\"Settings: %s\" % (file_name))\n",
        "print (\"---------------------------------------\")\n",
        "if not os.path.exists(\"./results\"):\n",
        "  os.makedirs(\"./results\")\n",
        "if save_models and not os.path.exists(\"./pytorch_models\"):\n",
        "  os.makedirs(\"./pytorch_models\")\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "state_dim = env.state_dim\n",
        "action_dim = env.action_dim\n",
        "max_action = env.max_action"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------\n",
            "Settings: TD3_car_8\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1t-c_r02aSq",
        "colab_type": "code",
        "outputId": "6105ff8e-8d12-466b-ceac-8d8f41f3f90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "env.reset()\n",
        "action = env.sample_action()\n",
        "new_obs, reward, done = env.step(action)\n",
        "#print(type(new_obs), reward, done)\n",
        "\n",
        "policy = ai.TD3(state_dim, action_dim, max_action)\n",
        "replay_buffer = ai.ReplayBuffer()\n",
        "evaluations = [evaluate_policy(policy)]\n",
        "\n",
        "work_dir = mkdir('exp', 'brs')\n",
        "monitor_dir = mkdir(work_dir, 'monitor')\n",
        "max_episode_steps = env._max_episode_steps\n",
        "\n",
        "total_timesteps = 0\n",
        "timesteps_since_eval = 0\n",
        "episode_num = 0\n",
        "done = True\n",
        "t0 = time.time()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step Function :: Boundary hit 50 times at location::463.95::635.00 On Road Steps Percentage: 34.77\n",
            "Step Function :: Boundary hit 50 times at location::401.83::635.00 On Road Steps Percentage: 31.33\n",
            "Step Function :: Boundary hit 50 times at location::433.96::635.00 On Road Steps Percentage: 37.95\n",
            "Step Function :: Boundary hit 50 times at location::412.60::635.00 On Road Steps Percentage: 32.84\n",
            "Step Function :: Boundary hit 50 times at location::449.45::635.00 On Road Steps Percentage: 42.59\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1690.400000\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-yikYV4Nlvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episode_reward = 0\n",
        "f = open(\"/content/drive/My Drive/EVA_Endgame_Model/stats.csv\", \"w\")\n",
        "f.write(\"total_timesteps, episode_num, episode_reward, done, on_road_count, off_road_count\\n\")\n",
        "f.close()\n",
        "re_train_flag = False\n",
        "\n",
        "if (re_train_flag):\n",
        "  policy.load(file_name, \"/content/drive/My Drive/EVA_Endgame_Model\")\n",
        "  replay_buffer, iter_count = load_rb(rb_file)\n",
        "  total_timesteps = int(iter_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evHbfk9S2bJx",
        "colab_type": "code",
        "outputId": "fec45a4b-9a7e-4858-eb56-fab65b6bdce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while total_timesteps < max_timesteps:\n",
        "  \n",
        "  # If the episode is done\n",
        "  if done:\n",
        "\n",
        "    # If we are not at the very beginning, we start the training process of the model\n",
        "    if (total_timesteps != 0):\n",
        "      print(\"Total Timesteps: {} Episode Num: {} Reward: {} episode_timesteps: {}  On Road Step Percentage: {:.2f}\".format(total_timesteps, episode_num, episode_reward, episode_timesteps, (env.episode_onroad*100/(episode_timesteps+1))))\n",
        "      policy.train(replay_buffer, episode_timesteps, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\n",
        "\n",
        "    # We evaluate the episode and we save the policy\n",
        "    if timesteps_since_eval >= eval_freq:\n",
        "      timesteps_since_eval %= eval_freq\n",
        "      evaluations.append(evaluate_policy(policy))\n",
        "      file_name = \"%s_%s_%s\" % (\"TD3_car\", str(seed), str(total_timesteps))\n",
        "      if save_models: policy.save(file_name, directory=\"./pytorch_models\")\n",
        "      policy.save(file_name, directory=\"/content/drive/My Drive/EVA_Endgame_Model\")\n",
        "      #save_rb(replay_buffer, rb_file, total_timesteps)\n",
        "      np.save(\"./results/%s\" % (file_name), evaluations)\n",
        "    \n",
        "    # When the training step is done, we reset the state of the environment\n",
        "    obs = env.reset()\n",
        "    \n",
        "    # Set the Done to False\n",
        "    done = False\n",
        "    \n",
        "    # Set rewards and episode timesteps to zero\n",
        "    episode_reward = 0\n",
        "    episode_timesteps = 0\n",
        "    episode_num += 1\n",
        "  \n",
        "  # Before 10000 timesteps, we play random actions\n",
        "  if total_timesteps < start_timesteps:\n",
        "    action = env.sample_action()\n",
        "  else: # After 10000 timesteps, we switch to the model  \n",
        "      action = policy.select_action(obs)\n",
        "      # If the explore_noise parameter is not 0, we add noise to the action and we clip it\n",
        "      if expl_noise != 0:\n",
        "          action = (action + np.random.normal(0, expl_noise, size=1)).clip(-max_action, max_action)[0]\n",
        "  \n",
        "  # The agent performs the action in the environment, then reaches the next state and receives the reward\n",
        "  new_obs, reward, done = env.step(action)\n",
        "  \n",
        "  # We check if the episode is done\n",
        "  done_bool = 0 if episode_timesteps + 1 == env._max_episode_steps else float(done)\n",
        "  \n",
        "  # We increase the total reward\n",
        "  episode_reward += reward\n",
        "  \n",
        "  # We store the new transition into the Experience Replay memory (ReplayBuffer)\n",
        "  replay_buffer.add((obs, new_obs, action, reward, done_bool))\n",
        "  update_stats(total_timesteps, episode_num, episode_reward, done, env.on_road_count, env.off_road_count)\n",
        "\n",
        "  # We update the state, the episode timestep, the total timesteps, and the timesteps since the evaluation of the policy\n",
        "  obs = new_obs\n",
        "  episode_timesteps += 1\n",
        "  total_timesteps += 1\n",
        "  timesteps_since_eval += 1\n",
        "\n",
        "# We add the last policy evaluation to our list of evaluations and we save our model\n",
        "evaluations.append(evaluate_policy(policy))\n",
        "if save_models: policy.save(\"%s\" % (file_name), directory=\"./pytorch_models\")\n",
        "np.save(\"./results/%s\" % (file_name), evaluations)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step Function :: Completed steps limit at location::813.70::384.06 On Road Steps Percentage: 19.81\n",
            "Total Timesteps: 5001 Episode Num: 1 Reward: -20266.0 episode_timesteps: 5001  On Road Step Percentage: 19.81\n",
            "Step Function :: Completed steps limit at location::118.56::601.08 On Road Steps Percentage: 7.98\n",
            "Step Function :: Completed steps limit at location::126.07::583.45 On Road Steps Percentage: 6.68\n",
            "Step Function :: Completed steps limit at location::148.64::599.23 On Road Steps Percentage: 8.04\n",
            "Step Function :: Completed steps limit at location::125.67::599.41 On Road Steps Percentage: 7.46\n",
            "Step Function :: Completed steps limit at location::102.66::594.30 On Road Steps Percentage: 7.66\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -23378.000000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::25.00::409.37 On Road Steps Percentage: 11.16\n",
            "Total Timesteps: 5430 Episode Num: 2 Reward: -2524.5 episode_timesteps: 429  On Road Step Percentage: 11.16\n",
            "Step Function :: Boundary hit 50 times at location::333.63::25.00 On Road Steps Percentage: 25.68\n",
            "Total Timesteps: 7279 Episode Num: 3 Reward: -7726.0 episode_timesteps: 1849  On Road Step Percentage: 25.68\n",
            "Step Function :: Boundary hit 50 times at location::25.00::168.23 On Road Steps Percentage: 13.44\n",
            "Total Timesteps: 8357 Episode Num: 4 Reward: -5348.0 episode_timesteps: 1078  On Road Step Percentage: 13.44\n",
            "Step Function :: Boundary hit 50 times at location::374.46::25.00 On Road Steps Percentage: 30.34\n",
            "Total Timesteps: 9503 Episode Num: 5 Reward: -4921.5 episode_timesteps: 1146  On Road Step Percentage: 30.34\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1789:: On Road Steps Percentage: 40.45\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Completed steps limit at location::497.95::311.65 On Road Steps Percentage: 6.94\n",
            "Total Timesteps: 16293 Episode Num: 6 Reward: -28361.0 episode_timesteps: 6790  On Road Step Percentage: 15.77\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 697:: On Road Steps Percentage: 40.97\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 748:: On Road Steps Percentage: 39.25\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 729:: On Road Steps Percentage: 15.75\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1614:: On Road Steps Percentage: 63.41\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1077:: On Road Steps Percentage: 29.50\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 703:: On Road Steps Percentage: 18.18\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 752:: On Road Steps Percentage: 85.92\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 737:: On Road Steps Percentage: 19.65\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 743:: On Road Steps Percentage: 47.18\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 832:: On Road Steps Percentage: 42.74\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 866:: On Road Steps Percentage: 56.98\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1104:: On Road Steps Percentage: 34.39\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1421:: On Road Steps Percentage: 65.82\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::706.61::25.00 On Road Steps Percentage: 10.44\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -6622.500000\n",
            "---------------------------------------\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 825:: On Road Steps Percentage: 38.26\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 873:: On Road Steps Percentage: 57.09\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1086:: On Road Steps Percentage: 22.45\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 19077 Episode Num: 7 Reward: -8313.0 episode_timesteps: 2784  On Road Step Percentage: 38.03\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1297:: On Road Steps Percentage: 35.82\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 746:: On Road Steps Percentage: 10.84\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 750:: On Road Steps Percentage: 14.78\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 21870 Episode Num: 8 Reward: -10281.0 episode_timesteps: 2793  On Road Step Percentage: 23.51\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1102:: On Road Steps Percentage: 80.96\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1763:: On Road Steps Percentage: 33.11\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 814:: On Road Steps Percentage: 7.24\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1448:: On Road Steps Percentage: 32.30\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1149:: On Road Steps Percentage: 36.87\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 908:: On Road Steps Percentage: 37.95\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1805:: On Road Steps Percentage: 48.17\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1053:: On Road Steps Percentage: 40.61\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 790:: On Road Steps Percentage: 7.71\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1551:: On Road Steps Percentage: 57.09\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 929:: On Road Steps Percentage: 11.94\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 807:: On Road Steps Percentage: 63.37\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1563:: On Road Steps Percentage: 56.14\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 916:: On Road Steps Percentage: 14.07\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 982:: On Road Steps Percentage: 58.60\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -10246.700000\n",
            "---------------------------------------\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1625:: On Road Steps Percentage: 62.36\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 401:: On Road Steps Percentage: 12.69\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 580:: On Road Steps Percentage: 22.72\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 24476 Episode Num: 9 Reward: -6646.0 episode_timesteps: 2606  On Road Step Percentage: 45.91\n",
            "Step Function :: Boundary hit 50 times at location::575.50::635.00 On Road Steps Percentage: 72.36\n",
            "Total Timesteps: 25336 Episode Num: 10 Reward: -1763.0 episode_timesteps: 860  On Road Step Percentage: 72.36\n",
            "Step Function :: Boundary hit 50 times at location::596.46::635.00 On Road Steps Percentage: 74.77\n",
            "Step Function :: Boundary hit 50 times at location::571.84::635.00 On Road Steps Percentage: 80.82\n",
            "Step Function :: Boundary hit 50 times at location::577.88::635.00 On Road Steps Percentage: 80.29\n",
            "Step Function :: Boundary hit 50 times at location::647.49::635.00 On Road Steps Percentage: 78.13\n",
            "Step Function :: Boundary hit 50 times at location::654.00::635.00 On Road Steps Percentage: 75.83\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1202.300000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::570.20::635.00 On Road Steps Percentage: 82.94\n",
            "Total Timesteps: 26021 Episode Num: 11 Reward: -1057.0 episode_timesteps: 685  On Road Step Percentage: 82.94\n",
            "Step Function :: Boundary hit 50 times at location::570.25::635.00 On Road Steps Percentage: 68.81\n",
            "Total Timesteps: 26892 Episode Num: 12 Reward: -1894.5 episode_timesteps: 871  On Road Step Percentage: 68.81\n",
            "Step Function :: Boundary hit 50 times at location::707.63::635.00 On Road Steps Percentage: 72.44\n",
            "Total Timesteps: 27497 Episode Num: 13 Reward: -1216.0 episode_timesteps: 605  On Road Step Percentage: 72.44\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 912:: On Road Steps Percentage: 80.39\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::625.62::25.00 On Road Steps Percentage: 16.00\n",
            "Total Timesteps: 29239 Episode Num: 14 Reward: -4585.0 episode_timesteps: 1742  On Road Step Percentage: 49.74\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 570:: On Road Steps Percentage: 33.98\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 966:: On Road Steps Percentage: 25.65\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 898:: On Road Steps Percentage: 10.79\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 31673 Episode Num: 15 Reward: -9225.0 episode_timesteps: 2434  On Road Step Percentage: 22.14\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1296:: On Road Steps Percentage: 85.43\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 837:: On Road Steps Percentage: 22.79\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 913:: On Road Steps Percentage: 17.51\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 433:: On Road Steps Percentage: 44.47\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 896:: On Road Steps Percentage: 14.72\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 443:: On Road Steps Percentage: 10.36\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1281:: On Road Steps Percentage: 84.56\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 455:: On Road Steps Percentage: 10.75\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 501:: On Road Steps Percentage: 69.72\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 742:: On Road Steps Percentage: 95.56\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 534:: On Road Steps Percentage: 79.07\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 449:: On Road Steps Percentage: 10.22\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1230:: On Road Steps Percentage: 65.96\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 449:: On Road Steps Percentage: 10.22\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 471:: On Road Steps Percentage: 9.11\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -4933.600000\n",
            "---------------------------------------\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 743:: On Road Steps Percentage: 96.24\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 578:: On Road Steps Percentage: 37.13\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 834:: On Road Steps Percentage: 22.99\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 33828 Episode Num: 16 Reward: -4500.0 episode_timesteps: 2155  On Road Step Percentage: 52.09\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 2080:: On Road Steps Percentage: 55.79\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::706.12::25.00 On Road Steps Percentage: 23.77\n",
            "Total Timesteps: 36517 Episode Num: 17 Reward: -7351.5 episode_timesteps: 2689  On Road Step Percentage: 48.55\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 539:: On Road Steps Percentage: 35.37\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1176:: On Road Steps Percentage: 36.53\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::795.18::25.00 On Road Steps Percentage: 15.16\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1358:: On Road Steps Percentage: 33.33\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 735:: On Road Steps Percentage: 47.69\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 750:: On Road Steps Percentage: 22.77\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 562:: On Road Steps Percentage: 33.75\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1178:: On Road Steps Percentage: 40.12\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1010:: On Road Steps Percentage: 27.50\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1503:: On Road Steps Percentage: 63.23\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::795.47::25.00 On Road Steps Percentage: 14.81\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1490:: On Road Steps Percentage: 42.45\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1186:: On Road Steps Percentage: 53.83\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1024:: On Road Steps Percentage: 23.80\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -8131.300000\n",
            "---------------------------------------\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1723:: On Road Steps Percentage: 67.52\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1024:: On Road Steps Percentage: 24.00\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1128:: On Road Steps Percentage: 19.84\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 40392 Episode Num: 18 Reward: -10751.5 episode_timesteps: 3875  On Road Step Percentage: 42.16\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1808:: On Road Steps Percentage: 65.23\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1313:: On Road Steps Percentage: 21.92\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 987:: On Road Steps Percentage: 50.40\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 745:: On Road Steps Percentage: 90.35\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 990:: On Road Steps Percentage: 49.14\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1368:: On Road Steps Percentage: 25.35\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 847:: On Road Steps Percentage: 56.25\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 713:: On Road Steps Percentage: 30.11\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 983:: On Road Steps Percentage: 49.70\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Step Function :: Boundary hit 50 times at location::944.49::635.00 On Road Steps Percentage: 88.45\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 744:: On Road Steps Percentage: 92.08\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 890:: On Road Steps Percentage: 39.17\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1005:: On Road Steps Percentage: 21.17\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -6498.700000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::603.04::25.00 On Road Steps Percentage: 50.72\n",
            "Total Timesteps: 41718 Episode Num: 19 Reward: -4352.0 episode_timesteps: 1326  On Road Step Percentage: 50.72\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1209:: On Road Steps Percentage: 42.07\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 803:: On Road Steps Percentage: 33.83\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1115:: On Road Steps Percentage: 29.75\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 940::580####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 44845 Episode Num: 20 Reward: -10215.0 episode_timesteps: 3127  On Road Step Percentage: 35.58\n",
            "Step Function :: Boundary hit 50 times at location::987.81::635.00 On Road Steps Percentage: 83.17\n",
            "Total Timesteps: 45783 Episode Num: 21 Reward: -1056.0 episode_timesteps: 938  On Road Step Percentage: 83.17\n",
            "Step Function :: Boundary hit 50 times at location::995.18::635.00 On Road Steps Percentage: 83.81\n",
            "Step Function :: Boundary hit 50 times at location::992.03::635.00 On Road Steps Percentage: 82.76\n",
            "Step Function :: Boundary hit 50 times at location::937.85::635.00 On Road Steps Percentage: 88.85\n",
            "Step Function :: Boundary hit 50 times at location::939.67::635.00 On Road Steps Percentage: 85.46\n",
            "Step Function :: Boundary hit 50 times at location::993.27::635.00 On Road Steps Percentage: 83.28\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -959.900000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::994.59::635.00 On Road Steps Percentage: 85.04\n",
            "Total Timesteps: 46731 Episode Num: 22 Reward: -1003.0 episode_timesteps: 948  On Road Step Percentage: 85.04\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 750:: On Road Steps Percentage: 92.81\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1419:: On Road Steps Percentage: 30.92\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1386:: On Road Steps Percentage: 19.83\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 50286 Episode Num: 23 Reward: -10352.0 episode_timesteps: 3555  On Road Step Percentage: 39.68\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1641:: On Road Steps Percentage: 45.92\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1671:: On Road Steps Percentage: 18.18\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::765.81::25.00 On Road Steps Percentage: 11.64\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1325:: On Road Steps Percentage: 46.68\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 721:: On Road Steps Percentage: 31.44\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "Step Function :: Boundary hit 50 times at location::1404.00::624.44 On Road Steps Percentage: 81.37\n",
            "Step Function :: Boundary hit 50 times at location::1404.00::532.17 On Road Steps Percentage: 91.84\n",
            "Step Function :: Boundary hit 50 times at location::1404.00::626.77 On Road Steps Percentage: 97.64\n",
            "Step Function :: Boundary hit 50 times at location::1389.95::635.00 On Road Steps Percentage: 95.21\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -4883.100000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::1404.00::623.39 On Road Steps Percentage: 93.73\n",
            "Total Timesteps: 51609 Episode Num: 24 Reward: -1021.0 episode_timesteps: 1323  On Road Step Percentage: 93.73\n",
            "Step Function :: Boundary hit 50 times at location::1360.29::635.00 On Road Steps Percentage: 100.00\n",
            "Total Timesteps: 52829 Episode Num: 25 Reward: -642.0 episode_timesteps: 1220  On Road Step Percentage: 100.00\n",
            "Step Function :: Boundary hit 50 times at location::1404.00::624.97 On Road Steps Percentage: 98.24\n",
            "Total Timesteps: 54135 Episode Num: 26 Reward: -767.5 episode_timesteps: 1306  On Road Step Percentage: 98.24\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 2042:: On Road Steps Percentage: 58.30\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "Step Function :: Boundary hit 50 times at location::860.97::25.00 On Road Steps Percentage: 0.00\n",
            "Total Timesteps: 56492 Episode Num: 27 Reward: -6004.0 episode_timesteps: 2357  On Road Step Percentage: 50.51\n",
            "Step Function :: Boundary hit 50 times at location::778.79::635.00 On Road Steps Percentage: 65.21\n",
            "Step Function :: Boundary hit 50 times at location::767.51::635.00 On Road Steps Percentage: 65.79\n",
            "Step Function :: Boundary hit 50 times at location::776.53::635.00 On Road Steps Percentage: 65.12\n",
            "Step Function :: Boundary hit 50 times at location::937.38::635.00 On Road Steps Percentage: 80.04\n",
            "Step Function :: Boundary hit 50 times at location::994.22::635.00 On Road Steps Percentage: 75.02\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1570.600000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::786.83::635.00 On Road Steps Percentage: 64.49\n",
            "Total Timesteps: 57226 Episode Num: 28 Reward: -1708.5 episode_timesteps: 734  On Road Step Percentage: 64.49\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 940.00::580.00 Steps Taken 742:: On Road Steps Percentage: 98.79\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 1091:: On Road Steps Percentage: 31.87\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 1046:: On Road Steps Percentage: 16.05\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "Total Timesteps: 60105 Episode Num: 29 Reward: -8045.5 episode_timesteps: 2879  On Road Step Percentage: 43.40\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 2818:: On Road Steps Percentage: 54.63\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1137:: On Road Steps Percentage: 9.67\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 911:: On Road Steps Percentage: 38.71\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 380::220####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 3442:: On Road Steps Percentage: 28.75\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "Step Function :: Boundary hit 50 times at location::1046.72::25.00 On Road Steps Percentage: 14.41\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 2909:: On Road Steps Percentage: 52.34\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::852.69::25.00 On Road Steps Percentage: 6.09\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 810:: On Road Steps Percentage: 55.73\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 1100::200####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 1100.00::200.00 Steps Taken 2196:: On Road Steps Percentage: 43.06\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "Step Function :: Boundary hit 50 times at location::846.98::25.00 On Road Steps Percentage: 6.42\n",
            "*************Inside Step Function :: Hit the Goal 1: **************\n",
            "Goal: 380.00::220.00 Steps Taken 2478:: On Road Steps Percentage: 41.39\n",
            "******************************************************************************\n",
            "####Goal 1 Reset to 940::580####\n",
            "*************Inside Step Function :: Hit the Goal 2: **************\n",
            "Goal: 940.00::580.00 Steps Taken 1741:: On Road Steps Percentage: 41.10\n",
            "******************************************************************************\n",
            "####Goal 2 Reset to 380::220####\n",
            "*************Inside Step Function :: Hit the Goal 3: **************\n",
            "Goal: 380.00::220.00 Steps Taken 2716:: On Road Steps Percentage: 16.16\n",
            "******************************************************************************\n",
            "####Goal 3 Reset to 1100::200####\n",
            "*********** Hurray  3 Goals Hit *************\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -16321.000000\n",
            "---------------------------------------\n",
            "Step Function :: Boundary hit 50 times at location::957.07::635.00 On Road Steps Percentage: 87.20\n",
            "Total Timesteps: 60932 Episode Num: 30 Reward: -789.5 episode_timesteps: 827  On Road Step Percentage: 87.20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fd6eec080e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Timesteps: {} Episode Num: {} Reward: {} episode_timesteps: {}  On Road Step Percentage: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_onroad\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_timesteps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# We evaluate the episode and we save the policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ai.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, replay_buffer, iterations, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\u001b[0m\n\u001b[1;32m    371\u001b[0m       \u001b[0;31m# Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mtarget_Q1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_Q2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_stateImgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_stateValues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0;31m# Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ai.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state_img, state_val, action)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_conv_2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_conv_2_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_pool_2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_conv_2_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}