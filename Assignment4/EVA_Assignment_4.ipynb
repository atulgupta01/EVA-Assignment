{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA-Assignment-4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "40cd730f-f200-4d65-cc53-345c8f0ca050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "2eae566b-95de-4ecf-8d0d-f737c716b558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efd9d1399b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "006998ba-7750-4c5b-a042-1cd089d6e069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "84854e10-ec94-4010-df17-96a6a0dcae58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZyQrNSPJ_o7",
        "colab_type": "text"
      },
      "source": [
        "**First Model** - with following specifications\n",
        "\n",
        "1. No Batch Normalizations\n",
        "2. No Max Pooling\n",
        "3. No Drop outs\n",
        "4. No Change in Learning rate\n",
        "5. Number of parameters is very high (72K)\n",
        "\n",
        "This is not at all an ideal model as per the structure. The target network should have less than 15K parameters and accuracy of 99.4% on validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eyVxRtkGkEU",
        "colab_type": "code",
        "outputId": "73881329-8569-491f-9bc1-7312f198b3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 7*7\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 9*9\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(10, 20))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 18:28:34.927598 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0825 18:28:34.941245 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0825 18:28:34.943888 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 20, 20, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 1, 10)          64010     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 71,130\n",
            "Trainable params: 71,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "d5352a22-879b-4b48-b669-8da62d765d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 18:28:35.015347 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0825 18:28:35.036573 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "5d207abd-9a27-4e5b-a29b-6015c6066c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "W0825 18:28:35.123427 139628983064448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0825 18:28:35.263279 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.1461 - acc: 0.9558 - val_loss: 0.0575 - val_acc: 0.9821\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0530 - acc: 0.9842 - val_loss: 0.0501 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.0410 - val_acc: 0.9870\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0287 - acc: 0.9911 - val_loss: 0.0399 - val_acc: 0.9872\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0457 - val_acc: 0.9866\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0365 - val_acc: 0.9901\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.0444 - val_acc: 0.9888\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0470 - val_acc: 0.9881\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0479 - val_acc: 0.9881\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0401 - val_acc: 0.9899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efdc4535198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_INZ65pKvds",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, the validation accuracy is 99.74% (highest) and Training accuracy is 99.01% (Highest). The difference in accuracies suggest overfitting. Given these accuracies, it is not possible to improve the training and val accuracies to the desired level.\n",
        "\n",
        "Following 2 changes are suggested in the next network\n",
        "\n",
        "1. Add Maxpool to reduce the number of parameters - while adding maxpool, we look at the image and assume that the receptive field of 5*5 should be sufficient to generate the required curves for prediction. Hence maxpool to be added after few convolutions.\n",
        "2. Add 1*1 convolution - again to reduce the number of parameters.\n",
        "\n",
        "These two changes will also help in reducing the gap between Train and Val accuracies to certain extent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBOFN3j9Mlst",
        "colab_type": "text"
      },
      "source": [
        "**Second Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "de52c69f-b573-4293-e0dd-b80e26b07dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 10*10\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 14*14\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 8))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "W0825 18:30:06.475419 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 10)          6410      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQAItMNNlnl",
        "colab_type": "code",
        "outputId": "10c512ed-7260-423f-ad13-aa6e87eb3414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.1702 - acc: 0.9470 - val_loss: 0.0589 - val_acc: 0.9829\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0622 - acc: 0.9809 - val_loss: 0.0397 - val_acc: 0.9876\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0473 - acc: 0.9859 - val_loss: 0.0437 - val_acc: 0.9857\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0384 - acc: 0.9884 - val_loss: 0.0373 - val_acc: 0.9873\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0324 - acc: 0.9897 - val_loss: 0.0297 - val_acc: 0.9904\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0271 - acc: 0.9916 - val_loss: 0.0320 - val_acc: 0.9895\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.0238 - acc: 0.9926 - val_loss: 0.0327 - val_acc: 0.9895\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0211 - acc: 0.9933 - val_loss: 0.0282 - val_acc: 0.9916\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0313 - val_acc: 0.9909\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0332 - val_acc: 0.9909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd8c25bcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcuoek4CVgb",
        "colab_type": "text"
      },
      "source": [
        "In the above model, following 2 has been achieved. \n",
        "\n",
        "1. The number of parameters have reduced and it is now 13K (less than 15K). \n",
        "2. The difference between the Training and Testing accuracy has improved compared to last time. Training accuracy is at 99.44% (Highest) and Val accuracy is 99.16% (Highest). But this is not sufficient and we need to find ways to improve it further.\n",
        "\n",
        "Also, note that the training is slower and more consistent after the recent changes in the model.\n",
        "\n",
        "In the next model, following 2 changes are suggested\n",
        "\n",
        "1. Batch normalization helps in converging faster, we add batch normalization after the activation layer in our next model to improve the train and val accuracies.\n",
        "\n",
        "2. Increase the number of epochs to 30 for more learning and more consistent accuracy on Val set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-79VP99RB51_",
        "colab_type": "text"
      },
      "source": [
        "**Third Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU0IoIAnB89k",
        "colab_type": "code",
        "outputId": "b32e005b-c715-4066-e5fc-1b82a1f9033a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 10*10\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 14*14\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 8))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0825 18:31:40.979614 139628983064448 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 1, 1, 10)          6410      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,996\n",
            "Trainable params: 13,848\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbAC0LsWCDuk",
        "colab_type": "code",
        "outputId": "9c9791d1-a90e-43bb-d155-1dcb24be5c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 0.3614 - acc: 0.9421 - val_loss: 0.1173 - val_acc: 0.9838\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.1423 - acc: 0.9720 - val_loss: 0.0565 - val_acc: 0.9867\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0973 - acc: 0.9791 - val_loss: 0.0441 - val_acc: 0.9894\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 0.0720 - acc: 0.9837 - val_loss: 0.0395 - val_acc: 0.9890\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0617 - acc: 0.9858 - val_loss: 0.0385 - val_acc: 0.9901\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0515 - acc: 0.9877 - val_loss: 0.0364 - val_acc: 0.9911\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0446 - acc: 0.9889 - val_loss: 0.0307 - val_acc: 0.9921\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0406 - acc: 0.9900 - val_loss: 0.0315 - val_acc: 0.9908\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0356 - acc: 0.9911 - val_loss: 0.0307 - val_acc: 0.9906\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 0.0319 - acc: 0.9920 - val_loss: 0.0279 - val_acc: 0.9910\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0292 - acc: 0.9924 - val_loss: 0.0302 - val_acc: 0.9906\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0275 - acc: 0.9930 - val_loss: 0.0252 - val_acc: 0.9916\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0254 - acc: 0.9938 - val_loss: 0.0259 - val_acc: 0.9917\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0248 - acc: 0.9933 - val_loss: 0.0245 - val_acc: 0.9924\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0221 - acc: 0.9943 - val_loss: 0.0269 - val_acc: 0.9926\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0214 - acc: 0.9945 - val_loss: 0.0253 - val_acc: 0.9922\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 0.0187 - acc: 0.9949 - val_loss: 0.0265 - val_acc: 0.9916\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.0258 - val_acc: 0.9920\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 15s 257us/step - loss: 0.0168 - acc: 0.9958 - val_loss: 0.0235 - val_acc: 0.9923\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0176 - acc: 0.9953 - val_loss: 0.0252 - val_acc: 0.9922\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0156 - acc: 0.9959 - val_loss: 0.0319 - val_acc: 0.9908\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0151 - acc: 0.9960 - val_loss: 0.0281 - val_acc: 0.9921\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0136 - acc: 0.9966 - val_loss: 0.0270 - val_acc: 0.9916\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0139 - acc: 0.9963 - val_loss: 0.0249 - val_acc: 0.9923\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0301 - val_acc: 0.9909\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0123 - acc: 0.9968 - val_loss: 0.0239 - val_acc: 0.9919\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0283 - val_acc: 0.9908\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0123 - acc: 0.9966 - val_loss: 0.0279 - val_acc: 0.9910\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 15s 251us/step - loss: 0.0107 - acc: 0.9972 - val_loss: 0.0301 - val_acc: 0.9904\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0255 - val_acc: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd85b99278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07NfoKxRYC6",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy 99.72% (highest) and testing accuracy of 99.26% (Highest) has been achieved with the suggested model with 30 epochs. But the testing accuracies fluctuates between different values. This is not a sign of good learning by the model. The val accuracy fluctuations should not be so high in a good model.\n",
        "\n",
        "The further improvement can be achieved by changing the learning rate in such a way that the learning improves consistently or increasing the epochs.\n",
        "\n",
        "In the forth model following changes are suggested\n",
        "\n",
        "1. Learning rate is modified to improve learning. For this learning rate of 0.01 is added with a decay of 0.001. These learning rates are decided after few experiments.\n",
        "2. Dropout of 25% added to reduce overfitting and improve validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kuRFaZfGRRh",
        "colab_type": "text"
      },
      "source": [
        "**Forth Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8r84J4tGYn-",
        "colab_type": "code",
        "outputId": "f02a9e9e-f3e8-4ecf-c898-1a56efa55fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 10*10\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 14*14\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 8))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0825 18:39:16.532347 139628983064448 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 1, 1, 10)          6410      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,996\n",
            "Trainable params: 13,848\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspDZqwdGdsd",
        "colab_type": "code",
        "outputId": "cd4d7e1b-a701-44a3-e12f-bd44138d7b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.Adam(lr = 0.01, decay = 0.0001),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 18s 300us/step - loss: 0.2257 - acc: 0.9414 - val_loss: 0.0631 - val_acc: 0.9819\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 0.1034 - acc: 0.9707 - val_loss: 0.0456 - val_acc: 0.9846\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 0.0822 - acc: 0.9763 - val_loss: 0.0380 - val_acc: 0.9879\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0706 - acc: 0.9792 - val_loss: 0.0326 - val_acc: 0.9891\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0633 - acc: 0.9815 - val_loss: 0.0286 - val_acc: 0.9917\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0607 - acc: 0.9820 - val_loss: 0.0237 - val_acc: 0.9921\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0564 - acc: 0.9832 - val_loss: 0.0241 - val_acc: 0.9927\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 17s 283us/step - loss: 0.0535 - acc: 0.9842 - val_loss: 0.0247 - val_acc: 0.9919\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 0.0496 - acc: 0.9849 - val_loss: 0.0232 - val_acc: 0.9932\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0488 - acc: 0.9854 - val_loss: 0.0213 - val_acc: 0.9934\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0457 - acc: 0.9862 - val_loss: 0.0204 - val_acc: 0.9943\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 17s 281us/step - loss: 0.0423 - acc: 0.9874 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.0415 - acc: 0.9878 - val_loss: 0.0206 - val_acc: 0.9935\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0400 - acc: 0.9878 - val_loss: 0.0206 - val_acc: 0.9931\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0405 - acc: 0.9882 - val_loss: 0.0201 - val_acc: 0.9937\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0189 - val_acc: 0.9940\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0381 - acc: 0.9887 - val_loss: 0.0185 - val_acc: 0.9942\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0381 - acc: 0.9885 - val_loss: 0.0174 - val_acc: 0.9947\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 17s 276us/step - loss: 0.0370 - acc: 0.9891 - val_loss: 0.0178 - val_acc: 0.9945\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 17s 277us/step - loss: 0.0372 - acc: 0.9889 - val_loss: 0.0173 - val_acc: 0.9944\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0356 - acc: 0.9891 - val_loss: 0.0193 - val_acc: 0.9934\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 17s 280us/step - loss: 0.0344 - acc: 0.9896 - val_loss: 0.0189 - val_acc: 0.9942\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0359 - acc: 0.9893 - val_loss: 0.0168 - val_acc: 0.9948\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0336 - acc: 0.9899 - val_loss: 0.0178 - val_acc: 0.9947\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 17s 284us/step - loss: 0.0349 - acc: 0.9898 - val_loss: 0.0182 - val_acc: 0.9940\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 17s 285us/step - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0190 - val_acc: 0.9943\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 17s 289us/step - loss: 0.0339 - acc: 0.9893 - val_loss: 0.0176 - val_acc: 0.9947\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0168 - val_acc: 0.9950\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 17s 278us/step - loss: 0.0319 - acc: 0.9905 - val_loss: 0.0180 - val_acc: 0.9944\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 17s 279us/step - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0164 - val_acc: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd84c55da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZlUEtiZhnz2",
        "colab_type": "text"
      },
      "source": [
        "With the modified model, highest accuracy achieved is **99.50%** for the validation dataset. "
      ]
    }
  ]
}