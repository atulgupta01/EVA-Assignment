{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA-Assignment-4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7e1e7f3-af39-4645-8a84-b87d03c703bf"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "d56c063a-635d-4477-fb03-c3b184a6915b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f35283f5940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiL\nHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGi\nwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53\nFd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k\n3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj\n1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uX\nu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T\n9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drI\nzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe\n9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzu\nvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2\nd/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2\nsv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oL\nb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8M\nOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX\n/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR\n2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930t\nuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr7\n4mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4\nfnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8s\nqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrc\nHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvL\nlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANB\nMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cie\nvqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2\nuPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/\nlrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUz\nW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TT\nDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77\nrgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HD\nyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6\nFy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifr\nz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+e\nsL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH53\n73f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29m\nJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63\nrbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s\n2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/\nJredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rW\nhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6\nnP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uT\ndRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2\nS+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xm\nS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0x\nszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxa\nBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HSt\nAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWY\nRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii\n/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz\n22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v\n9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25\n+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LK\nAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vm\nmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV\n2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODY\nJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PN\nPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuT\ndLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4b\nn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "a58f6b34-6b93-497e-8cf6-96f91c386630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "e87f57cf-18df-4977-f546-2f835865b58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZyQrNSPJ_o7",
        "colab_type": "text"
      },
      "source": [
        "**First Model** - with following specifications\n",
        "\n",
        "1. No Batch Normalizations\n",
        "2. No Max Pooling\n",
        "3. No Drop outs\n",
        "4. No Change in Learning rate\n",
        "5. Number of parameters is very high (144K)\n",
        "\n",
        "This is not at all an ideal model as per the structure. The target network should have less than 15K parameters and accuracy of 99.4% on validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eyVxRtkGkEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "72f7b164-0350-49d0-b920-c200526f5ab9"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(32, 3, 3)) #Receptive field 7*7\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(32, 3, 3)) #Receptive field 9*9\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(10, 20))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0819 01:43:19.389158 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0819 01:43:19.404560 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0819 01:43:19.407217 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 20, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 20, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 1, 10)          128010    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 144,378\n",
            "Trainable params: 144,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "24af95de-34f5-4bd7-dd49-25359ae89b9f"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0819 01:43:19.489359 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0819 01:43:19.517405 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "e07db866-1cc5-47a7-e511-f17fae58d69b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "W0819 01:43:19.621427 139867541325696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0819 01:43:19.778202 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.1212 - acc: 0.9637 - val_loss: 0.0499 - val_acc: 0.9836\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0454 - acc: 0.9862 - val_loss: 0.0370 - val_acc: 0.9882\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0304 - acc: 0.9908 - val_loss: 0.0390 - val_acc: 0.9878\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0513 - val_acc: 0.9868\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 0.0164 - acc: 0.9949 - val_loss: 0.0446 - val_acc: 0.9890\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0369 - val_acc: 0.9894\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.0092 - acc: 0.9969 - val_loss: 0.0506 - val_acc: 0.9881\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0533 - val_acc: 0.9878\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0518 - val_acc: 0.9890\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0806 - val_acc: 0.9858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f354f7f0f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_INZ65pKvds",
        "colab_type": "text"
      },
      "source": [
        "As we can see above, the validation accuracy is 99.82% (highest) and Training accuracy is 98.93% (Highest). The difference in accuracies suggest overfitting. Given these accuracies, it is not possible to improve the training and val accuracies to the desired level.\n",
        "\n",
        "Following 2 changes are suggested in the next network\n",
        "\n",
        "1. Add Maxpool to reduce the number of parameters - while adding maxpool, we look at the image and assume that the receptive field of 5*5 should be sufficient to generate the required curves for prediction. Hence maxpool to be added after every 2 convolutions.\n",
        "2. Add 1*1 convolution - again to reduce the number of parameters.\n",
        "\n",
        "These two changes will also help in reducing the gap between Train and Val accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBOFN3j9Mlst",
        "colab_type": "text"
      },
      "source": [
        "**Second Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "1d25cf2e-40b4-4747-cf9b-5b5c06022926"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(32, 3, 3)) #Receptive field 10*10\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 11*11\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  \n",
            "W0819 01:44:57.579934 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 5, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,960\n",
            "Trainable params: 9,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHQAItMNNlnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "5b9add55-170d-40a0-a0c9-2181f29dfeda"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 158us/step - loss: 0.1706 - acc: 0.9499 - val_loss: 0.0603 - val_acc: 0.9796\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0634 - acc: 0.9804 - val_loss: 0.0494 - val_acc: 0.9841\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0507 - acc: 0.9843 - val_loss: 0.0424 - val_acc: 0.9856\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.0414 - acc: 0.9874 - val_loss: 0.0343 - val_acc: 0.9889\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0392 - val_acc: 0.9879\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0316 - acc: 0.9897 - val_loss: 0.0386 - val_acc: 0.9870\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0371 - val_acc: 0.9880\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.0255 - acc: 0.9915 - val_loss: 0.0380 - val_acc: 0.9884\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.0223 - acc: 0.9926 - val_loss: 0.0331 - val_acc: 0.9891\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0366 - val_acc: 0.9880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3528427d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcuoek4CVgb",
        "colab_type": "text"
      },
      "source": [
        "In the above model, following 2 has been achieved. \n",
        "\n",
        "1. The number of parameters have reduced and it is now 9K. \n",
        "2. The difference between the Training and Testing accuracy has improved compared to last time. Training accuracy is at 99.32% (Highest) and Val accuracy is 98.91% (Highest). But this is not sufficient and we need to find ways to improve it further.\n",
        "\n",
        "Also, note that the training is slower and more consistent after removing the dense layer.\n",
        "\n",
        "In the next model, following 2 changes are suggested\n",
        "\n",
        "1. Batch normalization helps in converging faster, we add batch normalization in our next model to improve the train and val accuracies.\n",
        "\n",
        "2. Increase the number of epochs to 30 for more learning and more consistent accuracy on Val set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-79VP99RB51_",
        "colab_type": "text"
      },
      "source": [
        "**Third Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU0IoIAnB89k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "c23eec54-890d-4d32-a2bb-ac6d10e4a199"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(32, 3, 3)) #Receptive field 10*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 11*11\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "W0819 01:46:29.508894 139867541325696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 5, 5, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,256\n",
            "Trainable params: 10,108\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbAC0LsWCDuk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08fe2935-042e-4eed-b75a-325483a94224"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.3844 - acc: 0.9379 - val_loss: 0.1136 - val_acc: 0.9851\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 14s 234us/step - loss: 0.1588 - acc: 0.9687 - val_loss: 0.0690 - val_acc: 0.9879\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 14s 234us/step - loss: 0.1106 - acc: 0.9755 - val_loss: 0.0520 - val_acc: 0.9888\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0904 - acc: 0.9789 - val_loss: 0.0425 - val_acc: 0.9906\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0718 - acc: 0.9827 - val_loss: 0.0416 - val_acc: 0.9893\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0652 - acc: 0.9837 - val_loss: 0.0391 - val_acc: 0.9899\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0564 - acc: 0.9857 - val_loss: 0.0327 - val_acc: 0.9906\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0498 - acc: 0.9875 - val_loss: 0.0300 - val_acc: 0.9916\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0466 - acc: 0.9881 - val_loss: 0.0283 - val_acc: 0.9914\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0427 - acc: 0.9894 - val_loss: 0.0296 - val_acc: 0.9910\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0384 - acc: 0.9904 - val_loss: 0.0355 - val_acc: 0.9901\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0371 - acc: 0.9900 - val_loss: 0.0339 - val_acc: 0.9893\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0334 - acc: 0.9911 - val_loss: 0.0321 - val_acc: 0.9903\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0305 - acc: 0.9921 - val_loss: 0.0312 - val_acc: 0.9902\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.0292 - acc: 0.9924 - val_loss: 0.0260 - val_acc: 0.9920\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0293 - acc: 0.9921 - val_loss: 0.0362 - val_acc: 0.9890\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0259 - acc: 0.9933 - val_loss: 0.0291 - val_acc: 0.9911\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0260 - acc: 0.9932 - val_loss: 0.0275 - val_acc: 0.9924\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0238 - acc: 0.9936 - val_loss: 0.0314 - val_acc: 0.9916\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.0253 - val_acc: 0.9918\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0218 - acc: 0.9942 - val_loss: 0.0283 - val_acc: 0.9918\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0216 - acc: 0.9939 - val_loss: 0.0255 - val_acc: 0.9921\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0208 - acc: 0.9942 - val_loss: 0.0266 - val_acc: 0.9916\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0188 - acc: 0.9949 - val_loss: 0.0261 - val_acc: 0.9923\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0297 - val_acc: 0.9904\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0190 - acc: 0.9946 - val_loss: 0.0250 - val_acc: 0.9923\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.0172 - acc: 0.9956 - val_loss: 0.0260 - val_acc: 0.9921\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.0175 - acc: 0.9956 - val_loss: 0.0277 - val_acc: 0.9914\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 14s 236us/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0276 - val_acc: 0.9918\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 0.0303 - val_acc: 0.9908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35162121d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07NfoKxRYC6",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy 99.54% (highest) and testing accuracy of 99.23% (Highest) has been achieved with the suggested model with 30 epochs. But the testing accuracies fluctuates between different values. This is not a sign of good learning by the model. The val accuracy fluctuations should not be so high in a good model.\n",
        "\n",
        "The further improvement can be achieved either by changing the learning rate in such a way that the learning improves consistently or increasing the epochs.\n",
        "\n",
        "In the forth model, learning rate is modified to improve learning. For this learning rate of 0.01 is added with a decay of 0.001. These learning rates are decided after few experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kuRFaZfGRRh",
        "colab_type": "text"
      },
      "source": [
        "**Forth Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8r84J4tGYn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "8afe58eb-fbf6-4d97-ddb8-4eb049cfbdb5"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, input_shape=(28,28,1))) #Receptive field 3*3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(16, 3, 3)) #Receptive field 5*5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 6*6\n",
        "model.add(Convolution2D(32, 3, 3)) #Receptive field 10*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D()) #Receptive field 11*11\n",
        "model.add(Convolution2D(10, 1))\n",
        "model.add(Convolution2D(10, 5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 10, 10, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 10, 10, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 5, 5, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,256\n",
            "Trainable params: 10,108\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RspDZqwdGdsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c7cbd0b-7539-4eb6-da00-f350813f5f68"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=optimizers.Adam(lr = 0.01, decay = 0.0001),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=30, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 16s 259us/step - loss: 0.1837 - acc: 0.9573 - val_loss: 0.0643 - val_acc: 0.9815\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0815 - acc: 0.9775 - val_loss: 0.0362 - val_acc: 0.9882\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0569 - acc: 0.9841 - val_loss: 0.0404 - val_acc: 0.9875\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0492 - acc: 0.9861 - val_loss: 0.0268 - val_acc: 0.9922\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0414 - acc: 0.9881 - val_loss: 0.0328 - val_acc: 0.9905\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 15s 245us/step - loss: 0.0351 - acc: 0.9895 - val_loss: 0.0256 - val_acc: 0.9924\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.0318 - acc: 0.9908 - val_loss: 0.0262 - val_acc: 0.9912\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0296 - acc: 0.9914 - val_loss: 0.0274 - val_acc: 0.9907\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0270 - acc: 0.9919 - val_loss: 0.0243 - val_acc: 0.9914\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.0217 - val_acc: 0.9920\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0227 - acc: 0.9933 - val_loss: 0.0245 - val_acc: 0.9921\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0195 - acc: 0.9942 - val_loss: 0.0256 - val_acc: 0.9924\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 15s 242us/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0199 - val_acc: 0.9931\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0172 - acc: 0.9951 - val_loss: 0.0218 - val_acc: 0.9924\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0219 - val_acc: 0.9931\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0147 - acc: 0.9958 - val_loss: 0.0247 - val_acc: 0.9920\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 14s 242us/step - loss: 0.0153 - acc: 0.9957 - val_loss: 0.0232 - val_acc: 0.9931\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 14s 240us/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0238 - val_acc: 0.9919\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0243 - val_acc: 0.9930\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 0.0244 - val_acc: 0.9918\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0241 - val_acc: 0.9926\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 14s 239us/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0238 - val_acc: 0.9923\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0251 - val_acc: 0.9922\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.0111 - acc: 0.9968 - val_loss: 0.0275 - val_acc: 0.9917\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 15s 244us/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.0258 - val_acc: 0.9908\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 15s 245us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0269 - val_acc: 0.9916\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0253 - val_acc: 0.9921\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 15s 255us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0244 - val_acc: 0.9919\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0255 - val_acc: 0.9922\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 15s 245us/step - loss: 0.0087 - acc: 0.9976 - val_loss: 0.0247 - val_acc: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34ca8bccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZlUEtiZhnz2",
        "colab_type": "text"
      },
      "source": [
        "With the modified model, highest accuracy achieved is **99.31%** for the validation dataset. \n",
        "\n",
        "Also, i tried dropout but that did not increase the accuracy further for the validation dataset."
      ]
    }
  ]
}